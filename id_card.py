# -*- coding: utf-8 -*-
"""Đinh_Thái_Phúc_21011622.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W4m7OhIrFA3wMRg7iAs1oll09K4bBcq9
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2


img = cv2.imread('/content/anhthez.jpg')
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.imshow(img_rgb)

# remove text from the document

kernel  = np.ones((7,7), np.uint8)
img = cv2.morphologyEx(img_rgb, cv2.MORPH_CLOSE, kernel, iterations=3)
plt.imshow(img)

# rid of the background
"""
  take the corner 20 pixels as the background, and GrabCut
  automatically determines the foreground and background
"""
mask = np.zeros(img.shape[:2],np.uint8)
bgdModel = np.zeros((1,65),np.float64) #nền
fgdModel = np.zeros((1,65),np.float64)  #đối tượng
rect = (20,20,img.shape[1]-20,img.shape[0]-20) # hình chữ nhật để giữ lại
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)  # phân tách đối tượng
mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img)

#using canny edege
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray = cv2.GaussianBlur(gray, (11, 11), 0)
# Edge Detection.
canny = cv2.Canny(gray, 0, 200)
canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))

plt.imshow(canny)

# contour detection
# Blank canvas.
con = np.zeros_like(img)
# Tìm đường viền cho các cạnh được phát hiện.
contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
# Chỉ giữ lại đường viền lớn nhất được phát hiện.
page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
con = cv2.drawContours(con, page, -1, (0, 255, 255), 3)

plt.imshow(con)

# detecting the corner points
# Blank canvas.
con = np.zeros_like(img)
# Lặp lại các đường viền.
for c in page:
  # Approximate the contour.
  epsilon = 0.02 * cv2.arcLength(c, True)
  corners = cv2.approxPolyDP(c, epsilon, True)
  # Nếu đường viền gần đúng của chúng ta có bốn điểm
  if len(corners) == 4:
      break
cv2.drawContours(con, c, -1, (0, 255, 255), 3)
cv2.drawContours(con, corners, -1, (0, 255, 0), 10)
# Sắp xếp các góc và chuyển đổi chúng thành hình dạng mong muốn.
corners = sorted(np.concatenate(corners).tolist())

# Displaying the corners.
for index, c in enumerate(corners):
  character = chr(65 + index)
  cv2.putText(con, character, tuple(c), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 1, cv2.LINE_AA)

plt.imshow(con)

# Rearranging the detected corners (Sắp xếp lại các góc)
# sử dụng 1 hàm để sắp xếp lại tọa độ của 4 góc
def order_points(pts):
  """
  Rearrange coordinates to order:
      top-left, top-right, bottom-right, bottom-left
  """
  rect = np.zeros((4, 2), dtype='float32')
  pts = np.array(pts)
  s = pts.sum(axis=1)  # tổng của các tọa độ x và y của mỗi điểm
  # Top-left point will have the smallest sum.
  rect[0] = pts[np.argmin(s)]
  # Bottom-right point will have the largest sum.
  rect[2] = pts[np.argmax(s)]

  diff = np.diff(pts, axis=1)  # chênh lệch giữa các tọa độ x và y
  # Top-right point will have the smallest difference.
  rect[1] = pts[np.argmin(diff)]
  # Bottom-left will have the largest difference.
  rect[3] = pts[np.argmax(diff)]
  # Return the ordered coordinates.
  return rect.astype('int').tolist()

# finding the destination coordinantes
def find_dest(pts):
    (tl, tr, br, bl) = pts
    # Finding the maximum width.
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    # Finding the maximum height.
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))
    # Final destination co-ordinates.
    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]

    return order_points(destination_corners)

# function to scan the documents:
def scan(img):
    # Resize image to workable size
    dim_limit = 1080
    max_dim = max(img.shape)
    if max_dim > dim_limit:
        resize_scale = dim_limit / max_dim
        img = cv2.resize(img, None, fx=resize_scale, fy=resize_scale)
    # Create a copy of resized original image for later use
    orig_img = img.copy()
    # Repeated Closing operation to remove text from the document.
    kernel = np.ones((5, 5), np.uint8)
    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)
    # GrabCut
    mask = np.zeros(img.shape[:2], np.uint8)
    bgdModel = np.zeros((1, 65), np.float64)
    fgdModel = np.zeros((1, 65), np.float64)
    rect = (20, 20, img.shape[1] - 20, img.shape[0] - 20)
    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
    img = img * mask2[:, :, np.newaxis]

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (11, 11), 0)
    # Edge Detection.
    canny = cv2.Canny(gray, 0, 200)
    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))

    # Finding contours for the detected edges.
    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
    # Keeping only the largest detected contour.
    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]

    # Detecting Edges through Contour approximation.
    # Loop over the contours.
    if len(page) == 0:
        return orig_img
    for c in page:
        # Approximate the contour.
        epsilon = 0.02 * cv2.arcLength(c, True)
        corners = cv2.approxPolyDP(c, epsilon, True)
        # If our approximated contour has four points.
        if len(corners) == 4:
            break
    # Sorting the corners and converting them to desired shape.
    corners = sorted(np.concatenate(corners).tolist())
    # For 4 corner points being detected.
    corners = order_points(corners)

    destination_corners = find_dest(corners)

    h, w = orig_img.shape[:2]
    # Getting the homography.
    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))
    # Perspective transform using homography.
    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),
                                flags=cv2.INTER_LINEAR)
    return final

# Example usage
img = cv2.imread("/content/anhthez.jpg")
scanned_image = scan(img)

plt.imshow(scanned_image)

import cv2
import matplotlib.pyplot as plt

scanned_image_color = cv2.cvtColor(scanned_image, cv2.COLOR_BGR2RGB)
plt.imshow(scanned_image_color)
plt.show()

gray = cv2.cvtColor(scanned_image_color, cv2.COLOR_BGR2GRAY)
plt.title("Gray image")
plt.imshow(gray, cmap = 'gray')

_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

plt.imshow(binary, cmap='gray')
plt.title("Thresholded Image")

plt.show()

contour, hierachy = cv2.findContours(binary.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

#draw all contours
test = scanned_image_color.copy()
for i in range(len(contour)):
  a = cv2.drawContours(test, contour, i, color = [255,0,0], thickness=5)
plt.imshow(a)

#draw chill contours
test = scanned_image_color.copy()
for i in range(len(contour)):
  if(hierachy[0][i][2] == -1):
    a = cv2.drawContours(test, contour, i, color = [255,0,0], thickness=2)
plt.imshow(a)

import pandas as pd

# Copy và vẽ hình chữ nhật lên ảnh
cp = scanned_image_color.copy()
rectang = cv2.rectangle(cp, (285, 190), (560,230), (0,255,0), 3)
rectang = cv2.rectangle(rectang, (210, 250), (600,290), (0,255,0), 3)
rectang = cv2.rectangle(rectang, (340, 310), (420,360), (0,255,0), 3)
rectang = cv2.rectangle(rectang, (425, 290), (620,320), (0,255,0), 3)
rectang = cv2.rectangle(rectang, (210, 370), (700,410), (0,255,0), 3)
plt.imshow(rectang)

# Danh sách tọa độ các hình chữ nhật
rects = [
    (285, 190, 560, 230),
    (210, 250, 600, 290),
    (340, 310, 420, 360),
    (425, 290, 620, 320),
    (210, 370, 700, 410)
]

cropped_images = []

for (x1, y1, x2, y2) in rects:
    cropped_image = scanned_image_color[y1:y2, x1:x2]
    cropped_images.append(cropped_image)


plt.show()

data = {
    "STT": [1, 2, 3, 4, 5],
    "Thông tin": ["ID", "Name", "Gender", "Date", "Origin"],
    "Ảnh crop": cropped_images
}

fig, axes = plt.subplots(1, len(cropped_images), figsize=(15, 5))

for ax, img in zip(axes, cropped_images):
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.axis('off')

plt.show()

img_id = cropped_images[0]
img_id_gray = cv2.cvtColor(img_id,cv2.COLOR_BGR2GRAY)
_, threshold_image = cv2.threshold(img_id_gray, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
contour2, hierarchy2 = cv2.findContours(threshold_image.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
test = img_id.copy()
for i in range(len(contour2)):
  if hierarchy2[0][i][3] != -1:
    x2, y2, w2, h2 = cv2.boundingRect(contour2[i])
    cv2.rectangle(test, (x2, y2), (x2+w2, y2+h2), color=[255, 0, 0], thickness=1)
plt.imshow(test)
plt.show()

cropped_images_list = []

for i in range(len(contour2)):
    if hierarchy2[0][i][3] != -1:
        x2, y2, w2, h2 = cv2.boundingRect(contour2[i])
        cropped_image = img_id[y2:y2+h2, x2:x2+w2]
        cropped_images_list.append(cropped_image)

num_cols = 6
num_rows = (len(cropped_images_list) + num_cols - 1)

fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))


for i, image in enumerate(cropped_images_list):
    row = i // num_cols
    col = i % num_cols
    axes[row, col].imshow(image)
    axes[row, col].axis('off')

for i in range(len(cropped_images_list), num_rows*num_cols):
    row = i // num_cols
    col = i % num_cols
    axes[row, col].axis('off')

plt.show()